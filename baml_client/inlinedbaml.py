###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "elastic.baml": "// Data model for Generated Elastic Certified Engineer Exam Questions (ECE)\nenum Category {\n  QUERY_DSL @description(\"Query DSL: Things like match, term, range, bool,, filter, script, exists etc.\")\n  AGGREGATIONS @description(\"Aggregations: terms, histograms, pipeline, top_hits, etc.\")\n  MAPPING @description(\"Dnyamic mapping, nested fields, keyword versus text.\")\n  INGEST @description(\"Ingest pipelines, reindexing, runtime fields, etc.\")\n  SCRIPTING @description(\"Use of the painless scripting language.\")\n}\n\nclass ElasticQuestion {\n  category Category @description(\"The category of the question\")\n  question string @description(\"The question posed in plain english that requires a person to interpret using reading comprehension at the 12th grade level.\")\n  answer string @description(\"The answer to the question in the form of a Elasticsearch DSL query.\")\n}\n\nclass ElasticSet {\n  corpus ElasticQuestion @description(\"The questions, answers and categories in the set\")\n  rating \"Good\" | \"Bad\" @description(\"The rating of the set\")\n}\n\nfunction GenerateElasticCertificationQuestion(subject: Category, context: ElasticSet[]) -> ElasticQuestion {\n  client \"openai/gpt-4.1\"\n  prompt #\"\n    {{_.role(\"system\")}}\n    You are an AI assistant trained to generated certification style questions for the Elastic Certified Engineer Exam. Your questions are targeted at the eCommerce sample dataset provided by Elastic. Your goal is to create realistic and varied questions that reflect how Elastic has historially evaluated potential engineers in a proctored setting. For each question you generate, you will also generate a cognate answer that will be evaluated by an in-production Elasticsearch cluster. \n\n    For each question you generate: \n    1. The question should be posed in plain english that requires a person to interpret using reading comprehension at the 6th grade level.\n    2. Use the eCommerce dataset fields and structure as the data context. \n    3. Vary the question by the category. We are choosing this category: {{subject}}. \n    4. Assign **ONE PRIMARY CATEGORY** to each question generated consistent with the category chosen. \n    5. Provide the **question text** and the **correct answer** in the form of a JSON object\n    6. Keep the syntax Elasticsearch DSL valid.\n    7. Make the questions exam-level: not trivial but not impossible. Think: \"can you reason through this if you were well prepared?\"\n\n    Format the output as a JSON object with the following schema:\n\n    ---\n    {{ctx.output_format}}\n    ---\n\n    {{_.role(\"assistant\")}}\n    {% set max_examples = 3 %}\n    {% if context %}\n      Here are some examples of questions and answers categorized for your convenience and context to improve the quality of your output. \n      {%if context.rating == \"Bad\" %}\n        {% for question in context[:max_examples] %}\n          Poor Example: {{question.corpus}}\n        {% endfor %}\n      {% elif context.rating == \"Good\" %}\n        {% for question in context[:max_examples] %}\n          Good Example: {{question.corpus}}\n        {% endfor %}\n      {% endif %}\n    {% endif %}\n\n    {{_.role(\"user\")}}\n    Generate a question and answer pair for the {{subject}} category. \n  \"#\n}\n\n\ntest ElasticCertificationQuestion {\n  functions [GenerateElasticCertificationQuestion]\n  args {\n    subject \"QUERY_DSL\"\n    context []\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.90.2\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
}

def get_baml_files():
    return file_map