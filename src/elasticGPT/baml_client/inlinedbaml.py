###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "elastic.baml": "// Data model for Generated Elastic Certified Engineer Exam Questions (ECE)\nenum Category {\n  QUERY_DSL @description(\"Query DSL: Things like match, term, range, bool,, filter, script, exists etc.\")\n  AGGREGATIONS @description(\"Aggregations: terms, histograms, pipeline, top_hits, etc.\")\n  SCRIPTING @description(\"Use of the painless scripting language.\")\n}\n\nclass ElasticQuestion {\n  category Category @description(\"The category of the question\")\n  question string @description(\"The question posed in plain english that requires a person to interpret using reading comprehension at the 12th grade level.\")\n  endpoint string @description(\"The endpoint of the Elasticsearch API that the question is asking about. Use the index name as the endpoint.\")\n  method \"GET\" | \"POST\" | \"PUT\" | \"DELETE\" @description(\"Be sure to include whether the operation is a GET, POST, PUT, DELETE, etc.\")\n  answer string @description(\"The answer to the question in the form of a Elasticsearch DSL query.\")\n}\n\nclass ElasticMultipleChoose {\n  question string @description(\"The question posed in plain english that requires a person to interpret using reading comprehension at the 12th grade level.Questions is a multiple choose e.g( Question? A: possible answer 1, B: possible answer 2, C: possible answer 3, D: possible answer 4)\")\n  answer string @description(\"The answer can only be one charactor from A to D\")\n}\nclass ElasticMultipleChooseValidation {\n  isValid true | false @description(\"simple true and false value\")\n  reason string @description(\"Explanation of why the question is valid or not\")\n  location string @description(\"Where in the enablement content related to the question/answer was found\")\n}\n\nclass ElasticMultipleChooseSet {\n  questionClass ElasticMultipleChoose @description(\"The multiple-choice question and its possible answers\")\n  validationClass ElasticMultipleChooseValidation @description(\"The validation result of the multiple-choice question, including its validity and reasoning\")\n}\nclass ElasticSet {\n  corpus ElasticQuestion @description(\"The questions, answers and categories in the set\")\n  rating \"Good\" | \"Bad\" @description(\"The rating of the set\")\n}\nfunction ValidateGeneratedQuestion(questionObject: ElasticMultipleChoose, enablementContent: string) -> ElasticMultipleChooseValidation {\n   // client \"openai/gpt-4o\"\n  client \"openai/gpt-4o\"\n  prompt #\"\n    {{_.role(\"system\")}}\n    You are an AI assistant tasked with validating questions generated from enablement content. Your goal is to determine if the question is relevant to the content and if it effectively assesses understanding of the material.\n\n    For validation:\n    1. Ensure the question is related to the enablement content in concepts, do not need to have exact wording.\n    2. Check if the question is clear.\n    3. Determine if the question is challenging yet fair, suitable for someone who has thoroughly reviewed the enablement content.\n    4. Ensure that only one of the provided answers is correct, and the rest are incorrect.\n    5. Verify that the question and answers accurately reflect the key concepts, roles, functions, and any other relevant details described in the enablement content.\n\n    question: \n    ---\n    {{questionObject.question}}\n    ---\n\n    enablement content:\n    ---\n    {{enablementContent}}\n    ---\n    // {{ctx.output_format}}\n    ---\n\n    {{_.role(\"assistant\")}}\n    {% set correct_answer = questionObject.answer %}\n    {% set options = [\"A\", \"B\", \"C\", \"D\"] %}\n    {% if questionObject.question in enablementContent and correct_answer in options %}\n      {% if enablementContent.contains(correct_answer) and options|reject('equalto', correct_answer)|map('in', enablementContent)|list|length == 0 %}\n        true\n      {% else %}\n        false\n      {% endif %}\n    {% else %}\n      false\n    {% endif %}\n  \"#\n}\n\nfunction GenerateQuestionFromEnablementFile(enablementContent: string, questionBank: ElasticMultipleChooseSet[]) -> ElasticMultipleChoose {\n  // client \"openai/gpt-4o\"\n  client \"openai/gpt-4o\"\n  prompt #\"\n    {{_.role(\"system\")}}\n    You are an AI assistant trained to generate questions based on enablement content provided in a text file. Your task is to create questions that test the knowledge of the content within the file. The questions should be realistic and reflect the depth of understanding expected from someone who has studied the enablement material.\n\n    For each question you generate:\n    1. The question should be posed in plain English that requires a person to interpret using reading comprehension at the 6th grade level.\n    2. Use the content of the enablement file as the data context. And question should not ask outside of enablement file.\n    3. Provide the **question text** and the **correct answer** in the form of a JSON object.\n    4. Ensure the questions are challenging yet fair, suitable for someone who has thoroughly reviewed the enablement content.\n    5. Provide any necessary context or background information that might be needed to answer the question.\n    6. The target is to help support engineer become better on understanding the subject matter and troubleshooting\n\n    Format the output as a JSON object with the following schema:\n\n    ---\n    // {{ctx.output_format}}\n    ---\n\n    {{_.role(\"assistant\")}}\n    {% set max_examples = 3 %}\n    {% set good_questions = question_bank | selectattr('validationClass.isValid', 'equalto', true) | map(attribute='questionClass') | list %}\n    {% if good_questions %}\n      Here are some examples of good questions to avoid generating similar ones:\n      {% for question in good_questions %}\n        Good Example: {{question}}\n      {% endfor %}\n    {% endif %}\n    ---\n\n    {{_.role(\"user\")}}\n    Here is the content of the enablement file:\n    ---\n    {{enablementContent}}\n    ---\n    {{_.role(\"user\")}}\n    Generate a question and answer pair based on the enablement content, ensuring it is not similar to the good questions provided.\n  \"#\n}\n\nfunction GenerateElasticCertificationQuestion(subject: Category, index: string, mapping: string, data: string, context: ElasticSet[]) -> ElasticQuestion {\n  // client \"openai/gpt-4.1\"\n  client \"openai/gpt-4o\"\n  prompt #\"\n    {{_.role(\"system\")}}\n    You are an AI assistant trained to generated certification style questions for the Elastic Certified Engineer Exam. Your questions are targeted at the mapping provided by the user. Your goal is to create realistic and varied questions that reflect how Elastic has historially evaluated potential engineers in a proctored setting. For each question you generate, you will also generate a cognate answer that will be evaluated by an in-production Elasticsearch cluster. \n\n    For each question you generate: \n    1. The question should be posed in plain english that requires a person to interpret using reading comprehension at the 6th grade level.\n    2. Use the mapping fields and example data as the data context. \n    3. Vary the question by the category. We are choosing this category: {{subject}}. \n    4. Assign **ONE PRIMARY CATEGORY** to each question generated consistent with the category chosen. \n    5. Provide the **question text** and the **correct answer** in the form of a JSON object\n    6. Keep the syntax Elasticsearch DSL valid.\n    7. Make the questions exam-level: not trivial but not impossible. Think: \"can you reason through this if you were well prepared?\"\n    8. Provide the endpoint of the Elasticsearch API that the question is asking about. Use the index name as the endpoint. The index name is: {{index}}. \n\n    Format the output as a JSON object with the following schema:\n\n    ---\n    {{ctx.output_format}}\n    ---\n\n    {{_.role(\"assistant\")}}\n    {% set max_examples = 3 %}\n    {% if context %}\n      Here are some examples of questions and answers categorized for your convenience and context to improve the quality of your output. \n      {% for question in context[:max_examples] %}\n        {% if question.rating == \"Bad\" %}\n          Poor Example: {{question.corpus}}\n        {% elif question.rating == \"Good\" %}\n          Good Example: {{question.corpus}}\n        {% endif %}\n      {% endfor %}\n    {% endif %}\n    ---\n\n    {{_.role(\"user\")}}\n    Here is the mapping of the index:\n    {{mapping}}\n\n    Here is some example data from the index:\n    {{data}}\n\n    {{_.role(\"user\")}}\n    Generate a question and answer pair for the {{subject}} category. \n  \"#\n}\n\n\ntest ElasticCertificationQuestion {\n  functions [GenerateElasticCertificationQuestion]\n  args {\n    subject \"QUERY_DSL\"\n    index \"shakespeare\"\n    mapping #\"\n      {\n      'mappings': {\n            'properties': {\n                'index': {'properties': {'_id': {'type': 'long'}, '_index': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}},\n                'line_id': {'type': 'integer'},\n                'line_number': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}},\n                'play_name': {'type': 'keyword'},\n                'speaker': {'type': 'keyword'},\n                'speech_number': {'type': 'integer'},\n                'text_entry': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}},\n                'type': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}\n            }\n        }\n    }\n    \"#\n    data #\"\n      {\n    'play_name': 'Julius Caesar',\n    'speech_number': 26,\n    'line_number': '3.1.53',\n    'text_entry': 'Is there no voice more worthy than my own',\n    'speaker': 'METELLUS CIMBER',\n    'type': 'line',\n    'line_id': 47508\n}\n    \"#\n    context []\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../src/elasticGPT\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.90.2\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
}

def get_baml_files():
    return file_map